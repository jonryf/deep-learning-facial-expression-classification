{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os, random, copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sigmoid and its derivative for activation & backprop\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def derivSigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions: ['fear', 'surprise', 'sadness', 'happiness', 'anger', 'disgust'] \n",
      "\n",
      "fear: 25 # of images\n",
      "surprise: 83 # of images\n",
      "sadness: 28 # of images\n",
      "happiness: 69 # of images\n",
      "anger: 45 # of images\n",
      "disgust: 59 # of images\n",
      "\n",
      "Balanced Set:\n",
      "happiness: 45 # of images\n",
      "anger: 45 # of images\n",
      "Converting from array to PIL Image\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# CSE 253: Programming Assignment 1\n",
    "# Code snippet by Michael\n",
    "# Winter 2020\n",
    "################################################################################\n",
    "# We've provided you with the dataset in PA1.zip\n",
    "################################################################################\n",
    "# To install PIL, refer to the instructions for your system:\n",
    "# https://pillow.readthedocs.io/en/5.2.x/installation.html\n",
    "################################################################################\n",
    "# If you don't have NumPy installed, please use the instructions here:\n",
    "# https://scipy.org/install.html\n",
    "################################################################################\n",
    "\n",
    "\n",
    "''' \n",
    "list of face expressions (contempt, neutral are excluded) are:\n",
    "1. anger\n",
    "2. disgust\n",
    "3. fear\n",
    "4. happiness\n",
    "5. sadness\n",
    "6. surprise\n",
    "'''\n",
    "\n",
    "def load_data(data_dir=\"./aligned/\"):\n",
    "\t\"\"\" Load all PNG images stored in your data directory into a list of NumPy\n",
    "\tarrays.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata_dir: The relative directory path to the CK+ image directory.\n",
    "\tReturns:\n",
    "\t\timages: A dictionary with keys as emotions and a list containing images associated with each key.\n",
    "\t\tcnt: A dictionary that stores the # of images in each emotion\n",
    "\t\"\"\"\n",
    "\timages = defaultdict(list)\n",
    "\n",
    "\t# Get the list of emotional directory:\n",
    "\tfor e in listdir(data_dir):\n",
    "\t\t# excluding any non-directory files\n",
    "\t\tif not os.path.isdir(os.path.join(data_dir, e)):\n",
    "\t\t\tcontinue\n",
    "\t\t# Get the list of image file names\n",
    "\t\tall_files = listdir(os.path.join(data_dir, e))\n",
    "\n",
    "\t\tfor file in all_files:\n",
    "\t\t\t# Load only image files as PIL images and convert to NumPy arrays\n",
    "\t\t\tif '.png' in file:\n",
    "\t\t\t\timg = Image.open(os.path.join(data_dir, e, file))\n",
    "\t\t\t\timages[e].append(np.array(img))\n",
    "\n",
    "\tprint(\"Emotions: {} \\n\".format(list(images.keys())))\n",
    "\n",
    "\tcnt = defaultdict(int)\n",
    "\tfor e in images.keys():\n",
    "\t\tprint(\"{}: {} # of images\".format(e, len(images[e])))\n",
    "\t\tcnt[e] = len(images[e])\n",
    "\treturn images, cnt\n",
    "\n",
    "def balanced_sampler(dataset, cnt, emotions):\n",
    "\t# this ensures everyone has the same balanced subset for model training, don't change this seed value\n",
    "\trandom.seed(20)\n",
    "\tprint(\"\\nBalanced Set:\")\n",
    "\tmin_cnt = min([cnt[e] for e in emotions])\n",
    "\tbalanced_subset = defaultdict(list)\n",
    "\tfor e in emotions:\n",
    "\t\tbalanced_subset[e] = copy.deepcopy(dataset[e])\n",
    "\t\trandom.shuffle(balanced_subset[e])\n",
    "\t\tbalanced_subset[e] = balanced_subset[e][:min_cnt]\n",
    "\t\tprint('{}: {} # of images'.format(e, len(balanced_subset[e])))\n",
    "\treturn balanced_subset\n",
    "\n",
    "def display_face(img):\n",
    "\t\"\"\" Display the input image and optionally save as a PNG.\n",
    "\n",
    "\tArgs:\n",
    "\t\timg: The NumPy array or image to display\n",
    "\n",
    "\tReturns: None\n",
    "\t\"\"\"\n",
    "\t# Convert img to PIL Image object (if it's an ndarray)\n",
    "\tif type(img) == np.ndarray:\n",
    "\t\tprint(\"Converting from array to PIL Image\")\n",
    "\t\timg = Image.fromarray(img)\n",
    "\n",
    "\t# Display the image\n",
    "\timg.show()\n",
    "\n",
    "\n",
    "# example on how to use it\n",
    "if __name__ == '__main__':\n",
    "\t# The relative path to your image directory\n",
    "\tdata_dir = \"./aligned/\"\n",
    "\tdataset, cnt = load_data(data_dir)\n",
    "\t# test with happiness and anger\n",
    "\timages = balanced_sampler(dataset, cnt, emotions=['happiness', 'anger'])\n",
    "\tdisplay_index = 0\n",
    "\tdisplay_face(images['anger'][display_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10 # number of sections after folding\n",
    "M = 50 # maximum number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list happiness as a 1, anger as a 0\n",
    "X = images['happiness'] + images['anger']\n",
    "y = [1] * 45 + [0] * 45\n",
    "\n",
    "#get my feature - label pairs zipped together\n",
    "all_happy_angry = list(zip(X,y))\n",
    "\n",
    "#randomize the dataset so I can fold properly\n",
    "\n",
    "random.shuffle(all_happy_angry)\n",
    "\n",
    "def kfold(data, k=10):\n",
    "    folds = []\n",
    "    size = int((1/k) * len(data))\n",
    "    for i in range(0,k):\n",
    "        folds.append(data[i*size : (i+1)*size])\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "folds = kfold(all_happy_angry)\n",
    "print(len(folds[0]) == len(folds[1]))\n",
    "print(len(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0e0ae704bac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtraining_procedure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-0e0ae704bac3>\u001b[0m in \u001b[0;36mtraining_procedure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmering/UCSD/CSE253/HW1/253_HW1/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mimage\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \t\t\"\"\"\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# quick check for the right dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from pca import PCA\n",
    "\n",
    "\n",
    "\n",
    "def transform(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    folds = kfold(all_happy_angry)\n",
    "    k = len(folds)\n",
    "    for fold in range(k):\n",
    "        # split data\n",
    "        val_data, test_data = folds[fold], folds[(fold + 1) % k]\n",
    "        train_data = None\n",
    "        for i in range(k):\n",
    "            if i is not fold or i is not ((fold + 1) % k):\n",
    "                if train is None:\n",
    "                    train_data = folds[i]\n",
    "                else:\n",
    "                    train = np.concatenate((train, folds[i]))\n",
    "\n",
    "        # PCA\n",
    "        train, test, val = transform(train), transform(test), transform(val)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.batch_gradient_descent()\n",
    "            \n",
    "            error = model.loss()\n",
    "            acc = model.\n",
    "            \n",
    "            print(\"Error {} {}\".format(model.loss(), ))\n",
    "        \n",
    "\n",
    "def test():\n",
    "    pass\n",
    "\n",
    "training_procedure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, lr, dim):\n",
    "        self.lr = lr\n",
    "        self.w = np.zeros(dim) \n",
    "    \n",
    "    def stochastic_gradient_descent(self, X, labels):\n",
    "        indices = [i for i in range(len(labels))]\n",
    "        np.random.shuffle(indices)\n",
    "        for i in indices:\n",
    "            \n",
    "            # make predition\n",
    "            data = X[i]\n",
    "            label = labels[i]\n",
    "            predicted = sigmoid(data.dot(self.w))\n",
    "            error = label - predicted\n",
    "            \n",
    "            # update weights\n",
    "            for i in range(len(self.w)):\n",
    "                grad = error * data[i]\n",
    "                self.w[i] += self.lr * grad\n",
    "            \n",
    "    def make_prediction(self, X):\n",
    "        return sigmoid(X.dot(self.w))\n",
    "\n",
    "    \n",
    "    def batch_gradient_descent(self, X, labels):\n",
    "        predicted = self.make_prediction(X)\n",
    "        error = labels - predicted\n",
    "        grad = X.T.dot(error)\n",
    "        self.w += self.lr * grad\n",
    "        \n",
    "\n",
    "    def loss(self, labels, predicted):\n",
    "        log_predicted = np.log(predicted)\n",
    "        cost = log_predicted*labels + (1 - labels) * log_predicted\n",
    "        return - cost.sum() / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(0.1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.loss(np.array([1,1]), np.array([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34657359027997264"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.loss(np.array([1,1]), np.array([0.5,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([[0.9,0.22,0.44], [0.0,0.22,0.44]])\n",
    "\n",
    "for i in range(50):\n",
    "    lr.stochastic_gradient_descent(test_data, np.array([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0921362 ,  0.31898668,  0.63797337])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17769581, 0.58683226])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.make_prediction(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1303491917261295"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.loss(np.array([0, 1]), lr.make_prediction(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 \n",
    "\n",
    "[0, 0, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_mapping = [\"fear\", \"surprise\", \"sadness\", \"happiness\", \"anger\", \"disgust\"]\n",
    "\n",
    "\n",
    "class SoftmaxRegression:\n",
    "    \n",
    "    def __init__(self, lr, dim, c):\n",
    "        self.lr = lr\n",
    "        self.w = np.zeros((dim, c)) \n",
    "    \n",
    "    def stochastic_gradient_descent(self, X, labels):\n",
    "        indices = [i for i in range(len(labels))]\n",
    "        np.random.shuffle(indices)\n",
    "        for i in indices:\n",
    "            \n",
    "            # make predition\n",
    "            data = X[i]\n",
    "            label = labels[i]\n",
    "            predicted = self.probabilities(data)\n",
    "            error = label - predicted\n",
    "            \n",
    "            # update weights\n",
    "            for i in range(len(self.w)):\n",
    "                grad = error * data[i]\n",
    "                self.w[i] += self.lr * grad\n",
    "            \n",
    "    def probabilities(self, X):\n",
    "        return np.exp(X.dot(self.w)) / np.sum(np.exp(X.dot(self.w)))\n",
    "\n",
    "    \n",
    "    def batch_gradient_descent(self, X, labels):\n",
    "        predicted = self.probabilities(X)\n",
    "        error = labels - predicted\n",
    "        grad = X.T.dot(error)\n",
    "        self.w += self.lr * grad\n",
    "        \n",
    "\n",
    "    def loss(self, labels, predicted):\n",
    "        return -np.sum(np.sum(labels.T.dot(np.log(predicted)))) # can't have zero values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.545177444479562"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = SoftmaxRegression(0.02, 4, 2)\n",
    "\n",
    "test_data = np.array([[0.3,0.22,0.44, 0.44], [0.0,0.12,0.2, 0.2]])\n",
    "\n",
    "\n",
    "\n",
    "softmax.loss(np.array([[1, 0],[1,0]]), softmax.probabilities(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    softmax.batch_gradient_descent(test_data, np.array([[1, 0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4298127 , -0.24781465],\n",
       "       [29.49552279, -0.30152344],\n",
       "       [49.50871442, -0.56311598],\n",
       "       [49.50871442, -0.56311598]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
